{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import cluster\n",
    "import pickle\n",
    "# import plotly.plotly as py\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import get_metro_features as gmf\n",
    "import get_city_proportion as gcp\n",
    "import plot_and_split as pas\n",
    "import datetime\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_dir = '~/Desktop/dataset/'\n",
    "dataset_dir = cur_dir + 'head'\n",
    "ext = '_head'\n",
    "CITYNAME = 'LasVegas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(dataset_dir + '/user' + ext + '.csv')\n",
    "reviews = pd.read_csv(dataset_dir + '/review' + ext + '.csv')\n",
    "businesses = pd.read_csv(dataset_dir + '/business' + ext + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ON': 8631, 'IL': 524, 'WI': 1344, 'QC': 2307, 'EDH': 1127, 'AZ': 15023, 'PA': 2863, 'BW': 927, 'OH': 3601, 'NC': 3656, 'NV': 9610}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "major_businesses, state_num = pas.eliminate_minor_states(businesses)\n",
    "# Manually define boundaries because that's the easiest way to do this\n",
    "boundaries = dict(AZ=dict(bot=31.30, top=37.0, left=-115.0, right=-109),\n",
    "                 NC=dict(bot=33.8, top=36.8, left=-84.4, right=-75.1),\n",
    "                 PA=dict(bot=39, top=42.3, left=-80.7, right=-74.6),\n",
    "                 NV=dict(bot=34.9, top=42.07, left=-120.1, right=-114.02)) \n",
    "# One odd point this doesn't clean for NV because of diagonal, but whatever, not worth a more advanced function\n",
    "for state in state_num:\n",
    "    if state not in boundaries.keys():\n",
    "        # All other states are clean\n",
    "        continue\n",
    "    # Filter the one's that do need to be filtered\n",
    "    major_businesses = major_businesses[(major_businesses.state != state) | (major_businesses['latitude'] > boundaries[state]['bot'])]\n",
    "    major_businesses = major_businesses[(major_businesses.state != state) | (major_businesses['latitude'] < boundaries[state]['top'])]\n",
    "    major_businesses = major_businesses[(major_businesses.state != state) | (major_businesses['longitude'] > boundaries[state]['left'])]\n",
    "    major_businesses = major_businesses[(major_businesses.state != state) | (major_businesses['longitude'] < boundaries[state]['right'])]\n",
    "\n",
    "# Also NC and SC should be combined, because its the same area \n",
    "major_businesses.loc[major_businesses.state=='SC', 'state'] = 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ON', 'NV', 'EDH', 'PA', 'WI', 'IL', 'BW', 'AZ', 'OH', 'NC', 'QC'}\n",
      "(49608, 101)\n",
      "(49608, 101)\n"
     ]
    }
   ],
   "source": [
    "states = set(major_businesses['state'])\n",
    "print(states)\n",
    "init = np.zeros((len(states), 2))\n",
    "for i, state in enumerate(states):\n",
    "    init_pt = major_businesses[major_businesses['state'] == state].sample(1)\n",
    "    init[i, 0] = init_pt['latitude']\n",
    "    init[i, 1] = init_pt['longitude']\n",
    "\n",
    "# It looks like we have one NaN in lat/lng\n",
    "major_businesses.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "clusters = pas.cluster_cities(major_businesses, k=11, iter=500, init=init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "major_businesses = major_businesses.assign(metro_area=pd.Series(clusters[1]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b = major_businesses.keys()\n",
    "# nonA = [ba for ba in b if 'Attributes' not in ba and 'attributes' not in ba and 'hours' not in ba]\n",
    "# major_businesses2 = major_businesses[nonA]\n",
    "# # major_businesses2.groupby('metro_area')\n",
    "# major_businesses2 = major_businesses2.rename(columns={'review_count':'biz_review_count'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_date = pd.to_datetime(users['yelping_since']).dt.date\n",
    "now_date = datetime.date(2017, 12, 1)\n",
    "users['weeks_on_yelp'] = (now_date - join_date).dt.days / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connections = gmf.link_for_metro(users, major_businesses, reviews)\n",
    "# This gives us percentage of reviews in each metro area\n",
    "perc_metro = gmf.calc_perc_metro(connections)\n",
    "# print(perc_metro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped. Now merge\n"
     ]
    }
   ],
   "source": [
    "num_visited = gmf.num_metros_visited(perc_metro)\n",
    "weeks_metro = gmf.calc_num_weeks_metro(num_visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51155, 3)\n",
      "evaluating metro: 0\n",
      "(51155, 5)\n",
      "evaluating metro: 1\n",
      "(51155, 7)\n",
      "evaluating metro: 2\n",
      "(51155, 9)\n",
      "evaluating metro: 3\n",
      "(51155, 11)\n",
      "evaluating metro: 4\n",
      "(51155, 13)\n",
      "evaluating metro: 5\n",
      "(51155, 15)\n",
      "evaluating metro: 6\n",
      "(51155, 17)\n",
      "evaluating metro: 7\n",
      "(51155, 19)\n",
      "evaluating metro: 8\n",
      "(51155, 21)\n",
      "evaluating metro: 9\n",
      "(51155, 23)\n",
      "evaluating metro: 10\n",
      "(51155, 25)\n"
     ]
    }
   ],
   "source": [
    "# review_metro = gmf.reviews_per_week_per_metro(weeks_metro)\n",
    "user_features = gmf.define_user_features(users, weeks_metro, clusters[0].shape[0])\n",
    "# user_features['num_metros_visited'] = perc_metro.groupby('user_id')['num_metros_visited'].nunique()\n",
    "# user_features = pd.merge(user_features, dnew, on='user_id', how='left')\n",
    "user_features.fillna(0, inplace=True)\n",
    "user_features = user_features.groupby('user_id').max()\n",
    "user_features = user_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 0.04556423  0.99543516  0.99647887  0.9948826   1.          1.          1.\n",
      "  0.99894217  0.99759089  1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "user_f = np.array(user_features[['m0_percent', # removed 'num_metros_visited', 'weeks_on_yelp', \n",
    "       'm0_weeks', 'm1_percent', 'm1_weeks', 'm2_percent', 'm2_weeks',\n",
    "       'm3_percent', 'm3_weeks', 'm4_percent', 'm4_weeks', 'm5_percent',\n",
    "       'm5_weeks', 'm6_percent', 'm6_weeks', 'm7_percent', 'm7_weeks',\n",
    "       'm8_percent', 'm8_weeks', 'm9_percent', 'm9_weeks', 'm10_percent',\n",
    "       'm10_weeks']])\n",
    "user_f = user_f.astype(float)\n",
    "initialization = np.zeros((11, user_f.shape[1]))\n",
    "for i in range(11):\n",
    "    initialization[i, 2*i] = 1\n",
    "print(np.max(initialization, axis=1))\n",
    "# print(initialization)\n",
    "# print(np.sum(user_f, axis=1)[0:20])\n",
    "# # print(user_features[0:5])\n",
    "# # user_fnorm = preprocessing.normalize(user_f, norm='l1', axis=0, copy=True, return_norm=False)\n",
    "user_clustering = cluster.vq.kmeans2(user_f, initialization, iter=600, minit='matrix')\n",
    "user_res = user_features.copy()\n",
    "user_res['group'] = user_clustering[1]\n",
    "print(np.max(user_clustering[0], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_res['cluster_dist'] = np.zeros(user_res.shape[0])\n",
    "cluster_keys = [k for k in user_res.keys() if k not in ['user_id', 'group', 'cluster_dist', 'num_metros_visited', 'weeks_on_yelp']]\n",
    "for m in range(1, clusters[0].shape[0]):\n",
    "    test_group = user_res.loc[user_res.group == m, cluster_keys]\n",
    "#     print(test_group)\n",
    "    user_res.loc[user_res.group == m, 'cluster_dist'] = np.linalg.norm(user_res.loc[user_res.group == m, cluster_keys] - \n",
    "                                                                user_clustering[0][m], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User city Toronto = 0\t 43.66, -79.58\n",
      "Biz city  Toronto = 0\t 43.70, -79.43\n",
      "===================================\n",
      "User city LasVegas = 1\t 36.13, -115.03\n",
      "Biz city  LasVegas = 1\t 36.12, -115.17\n",
      "===================================\n",
      "User city Edinburgh = 2\t 55.86, -3.62\n",
      "Biz city  Edinburgh = 2\t 55.95, -3.20\n",
      "===================================\n",
      "User city Pittsburgh = 3\t 40.42, -80.12\n",
      "Biz city  Pittsburgh = 3\t 40.44, -79.94\n",
      "===================================\n",
      "User city Madison = 4\t 43.07, -89.39\n",
      "Biz city  Madison = 4\t 43.08, -89.41\n",
      "===================================\n",
      "User city Champaign = 5\t 40.11, -88.26\n",
      "Biz city  Champaign = 5\t 40.11, -88.25\n",
      "===================================\n",
      "User city Stuttgart = 6\t 48.75, 9.19\n",
      "Biz city  Stuttgart = 6\t 48.77, 9.17\n",
      "===================================\n",
      "User city Phoenix = 7\t 33.50, -112.01\n",
      "Biz city  Phoenix = 7\t 33.49, -111.99\n",
      "===================================\n",
      "User city Cleveland = 8\t 41.40, -81.72\n",
      "Biz city  Cleveland = 8\t 41.42, -81.65\n",
      "===================================\n",
      "User city Charlotte = 9\t 35.21, -80.84\n",
      "Biz city  Charlotte = 9\t 35.22, -80.83\n",
      "===================================\n",
      "User city Montreal = 10\t 45.51, -73.59\n",
      "Biz city  Montreal = 10\t 45.51, -73.61\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "city_centers = dict(\n",
    "    Toronto=(43.66, -79.58),\n",
    "    LasVegas=(36.0, -115.0),\n",
    "    Edinburgh=(55.0, -3.19),\n",
    "    Pittsburgh=(40.12, -80.12),\n",
    "    Madison=(43.07, -89.38),\n",
    "    Champaign=(40.08, -88.29),\n",
    "    Stuttgart=(48.71, 9.23),\n",
    "    Phoenix=(33.39, -111.91),\n",
    "    Cleveland=(41.18, -81.49),\n",
    "    Charlotte=(35.25, -80.79),\n",
    "    Montreal=(45.58, -73.54)\n",
    ")\n",
    "\n",
    "def closest_value(compare, lat, lng):\n",
    "    mindist = 1e6\n",
    "    mindex = -1\n",
    "    for k in compare:\n",
    "        temp = np.linalg.norm([compare[k][0] - lat, compare[k][1] - lng])\n",
    "        if temp < mindist:\n",
    "            mindex = k\n",
    "            mindist = temp\n",
    "#             print('new mindist = {}'.format(mindist))\n",
    "    return mindex\n",
    "\n",
    "\n",
    "cities = dict()\n",
    "city_bs = dict()\n",
    "for i in range(clusters[0].shape[0]):\n",
    "    city_locals = user_res[user_res['group'] == i]\n",
    "    connection_locals = connections[connections['user_id'].isin(city_locals['user_id'])]\n",
    "    mean_lat, mean_lng = np.mean(connection_locals['latitude']), np.mean(connection_locals['longitude'])\n",
    "#     print(mean_lat, mean_lng)\n",
    "    city = closest_value(city_centers, mean_lat, mean_lng)\n",
    "    cities[city] = i\n",
    "    print('User city {} = {}\\t {:.2f}, {:.2f}'.format(city, i, mean_lat, mean_lng))\n",
    "    \n",
    "    # Now do businesses\n",
    "    business_locals = major_businesses[major_businesses['metro_area'] == i]\n",
    "    mean_lat, mean_lng = np.mean(business_locals['latitude']), np.mean(business_locals['longitude'])\n",
    "    city = closest_value(city_centers, mean_lat, mean_lng)\n",
    "    city_bs[city] = i\n",
    "    print('Biz city  {} = {}\\t {:.2f}, {:.2f}'.format(city, i, mean_lat, mean_lng))\n",
    "    print('===================================')\n",
    "# print(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "city_centers = \"\"\"\n",
    "#: \\tlat, lng =\\tCity\n",
    "0:\\t43.60, 79.50=\\tToronto\n",
    "1:\\t36.0, -115.0=\\tLas Vegas\n",
    "2:\\t55.0, -3.19=\\tEdinburgh\n",
    "3:\\t43.0, -79.9=\\tPittsburgh\n",
    "4:\\t43.07, -89.38=\\tMadison\n",
    "5:\\t40.08, -88.29=\\tChampaign\n",
    "6:\\t48.71, 9.23=\\tStuttgart\n",
    "7:\\t33.39, -111.91=\\tPhoenix\n",
    "8:\\t41.18, -81.49=\\tCleveland\n",
    "9:\\t35.25, -80.79=\\tCharlotte\n",
    "10:\\t45.58, -73.54=\\tMontreal\n",
    "\"\"\"\n",
    "# print(city_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 5002)\n",
      "(116, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:22: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:23: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n"
     ]
    }
   ],
   "source": [
    "def get_city_array(city_index, connections, user_res, businesses, savename=None):\n",
    "    local_users = user_res[user_res['group'] == city_index]\n",
    "    local_bizes = businesses[businesses['metro_area'] == city_index]\n",
    "    local_connections = connections[connections['user_id'].isin(local_users['user_id'])]\n",
    "    local_connections = local_connections[local_connections['business_id'].isin(local_bizes['business_id'])]\n",
    "                                    \n",
    "    local_users = set(local_connections.user_id)\n",
    "    local_businesses = set(local_connections.business_id)\n",
    "    local_data = local_connections['stars'].tolist()\n",
    "    local_col = local_connections.user_id.astype('category', categories=local_users).cat.codes\n",
    "    local_row = local_connections.business_id.astype('category', categories=local_businesses).cat.codes\n",
    "    local_sparse_matrix = csc_matrix((local_data, (local_row, local_col)), \n",
    "                                     shape=(len(local_businesses), len(local_users)))\n",
    "    \n",
    "    # For tourist, get new users but same businesses\n",
    "    tourist_users = user_res[user_res['group'] != city_index]\n",
    "    tourist_connections = connections[connections['user_id'].isin(tourist_users['user_id'])]\n",
    "    tourist_connections = tourist_connections[tourist_connections['business_id'].isin(local_bizes['business_id'])]\n",
    "    \n",
    "    tourist_users = set(tourist_connections.user_id)\n",
    "    tourist_data = tourist_connections['stars'].tolist()\n",
    "    tourist_col = tourist_connections.user_id.astype('category', categories=tourist_users).cat.codes\n",
    "    tourist_row = tourist_connections.business_id.astype('category', categories=local_businesses).cat.codes\n",
    "    tourist_sparse_matrix = csc_matrix((tourist_data, (tourist_row, tourist_col)), \n",
    "                                       shape=(len(local_businesses), len(tourist_users)))\n",
    "    \n",
    "    print(local_sparse_matrix.shape)\n",
    "    print(tourist_sparse_matrix.shape)\n",
    "    if savename is not None:\n",
    "        pickle.dump(local_sparse_matrix, open('data/{}_local.pck'.format(savename), 'wb'))\n",
    "        pickle.dump(tourist_sparse_matrix, open('data/{}_tourist.pck'.format(savename), 'wb'))\n",
    "    return local_sparse_matrix,  tourist_sparse_matrix\n",
    "\n",
    "L, T = get_city_array(cities[CITYNAME], connections, user_res, major_businesses, CITYNAME)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user_res.keys()\n",
    "# LV_users = user_res[user_res['group'] == 1]\n",
    "# LV_businesses = major_businesses[major_businesses['metro_area'] == 1]\n",
    "# # LV_connections = connections[connections['user_id'].isin(m0_users['user_id'])]\n",
    "# print(connections.shape)\n",
    "# LV_connections = connections[connections['user_id'].isin(LV_users['user_id'])]\n",
    "# print(LV_connections.shape)\n",
    "# LV_connections = LV_connections[LV_connections['business_id'].isin(LV_businesses['business_id'])]\n",
    "# print(LV_connections.shape)\n",
    "\n",
    "\n",
    "# # connections.user_id\n",
    "\n",
    "# LV_local = LV_connections.pivot(index='user_id', columns='business_id', values='stars')\n",
    "# # print(LV_local)\n",
    "# print(LV_local.shape)\n",
    "# LV_nonnan = LV_local[np.isnan(LV_local) == False]\n",
    "# # ~np.isnan(LV_local) == True\n",
    "# print(LV_nonnan)\n",
    "# # LV_sparse = scipy.sparse.csr_matrix(LV_local.values.T)\n",
    "# # print(LV_sparse.shape)\n",
    "\n",
    "# # c_maxes = connections.groupby(['user_id', 'business_id']).review_count.transform(max)\n",
    "# # c2 = connections[connections.review_count == c_maxes]\n",
    "# # # print(connections.shape)\n",
    "# # # print(c2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/Users/Andy/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# LV_users = set(LV_connections.user_id)\n",
    "# LV_businesses = set(LV_connections.business_id)\n",
    "\n",
    "# data = LV_connections['stars'].tolist()\n",
    "# col = LV_connections.user_id.astype('category', categories=LV_users).cat.codes\n",
    "# row = LV_connections.business_id.astype('category', categories=LV_businesses).cat.codes\n",
    "# sparse_matrix = csc_matrix((data, (row, col)), shape=(len(LV_businesses), len(LV_users)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
